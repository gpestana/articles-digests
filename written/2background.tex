\chapter{Background}

\section{Energy consumption in Scientific Computing}
\subsection{Literature review}

% initial explorations of ARM processors for scientific computing
According to  \cite{ACAT13ARM}, the computing requirements for HPC have 
increased particularly in recent
years. Projects of the magnitude and complexity of the Large Hadron Collider are
overwhelming examples of that fact. To achieve results like the discovering of
the Higgs boson and other significant scientific advances, it was necessary a 
 to distribute the processing tasks across several partners and institutions
through the WLCG. The equivalent capacity of such distributed systems was between 
80,000 and 100,000 x86-64 cores in 2012.
Further projects and discoveries will demand even more processing capacity from
the WLCG. For example, as stated by \cite{ACAT13ARM}, to upgrade the LHC 
detectors luminosity to its full power the datasets will increase sizes by 2-3
orders of magnitude and processing power will have to increase in proportion.


% heterogeneous high throughput scientific computing with APM X-gene and Intel Xeon Phi
% TODO intel vs ARM pointers
% 
In \cite{ACAT14ARMDAVID}, a server-purpose ARM machine is compared with the recent
Intel architectures, such as the recent Intel Xeon Phi and a dominating Intel product
intended for HPC workloads (Intel Xeon E5-2650). The workload for comparing
the architectures was ParfullCMS. They based the results on performance (events per
second) and scalability over power (watts). In addition to performance and energy
consumption comparisons, the paper describes the porting endeavors of the CMSSW to
an ARMv8 64-bits architecture.

%TODO describe better different architectures, side by side. 
%TODO describe better experiment setup
In \cite{ACAT14ARMDAVID}, they use an APM X-Gene 1 running on a development board. 
It consists of a 8 physical core processor running at 2.4GHz with 16GB DDR3 memory.
As the authors highlight, the firmware for managing processor ACPI power states was
not yet available when the study was made. Thus, it is expected that the energy 
performance will improve once the firmware is available \cite{ACAT14ARMDAVID}.

Under the circumstances of the experiment, the overall results show that APM X-Gene 
is 2.73 slower than Intel Xeon Phi. From the energy consumption performance (events
per second per watt), the Intel Xeon E-2650 is the most efficient, with APM X-Gene
presenting similar performances despite the absence of platform specific 
optimizations. Therefore, \cite{ACAT14ARMDAVID} concludes by stating that the APM
X-Gene 1 Server-On-Chip ARMv8 64-bit solution is relevant and potentially interesting
platform for heterogeneous high-density computing. 

\section{High Throughput Computing}
\subsection{Literature review}



\section{CERN and the LHC experiment}
\subsection{Literature review}



\section{Energy performance and measurement}
\subsection{Literature review}

% mining questions about software energy consumption
\textbf{on importance of energy consumption for engineers and scientists}
\\
The study conducted by \cite{QUESTIONS_ENERGY}, shows that engineers have been
considering energy consumption as an important factor when developing software.
It consists on an empirical study that aims to understand the opinions and
problems of software developers about energy efficiency. The data that sustain
the conclusions are  mined from
a well-known technical forum (\textit{StackOverflow} \cite{STACKOVERFLOW}).
Although the study is focused in an application-level energy efficiency, it
shows that developers are aware of the importance of energy efficiency in 
computational systems. When trying to understand in depth what questions arise 
more frequently, it is shown that measurement techniques is amongst the most
asked questions by developers. In addition, the study ascertains that the 
\textit{"lack of tool support"} is an important handicap for the development of 
energy efficient software.






\section{ARM architecture}
\subsection{Literature review}


% initial explorations of ARM processors for scientific computing
In \cite{ACAT13ARM}:

- After 2015, processors have hit scaling limits. Two different paths started to be
taken on the processor industry:  development of multiprocessor architectures that
allow to run parallel tasks and the time clock frequency - which have been
increasing throughout the years - stabilized.

- Most High Physics Computing systems run in clusters of several cores.
Additional cores are parallelized and can run at the same time, which allows the
system to scale. However, also commodities such memory, I/O streams and energy
scale proportionally in such architectures.
 
 
